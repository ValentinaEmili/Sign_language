{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinaEmili/Sign_language/blob/main/Hands_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kCtae26tygt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b560dfbd-9cbe-4ca4-8813-5df00363ee82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q yt_dlp"
      ],
      "metadata": {
        "id": "SFrlTkPRGrMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3bed9b-17e3-43ac-e106-f4ff0e29c54e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m143.4/172.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/3.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import requests\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import yt_dlp"
      ],
      "metadata": {
        "id": "nibhY2zmQX79"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the JSON data\n",
        "js_file = pd.read_json(\"/content/drive/MyDrive/NLP/WLASL_v0.3.json\")\n",
        "folder = \"/content/drive/MyDrive/NLP/dataset/\"\n",
        "\n",
        "training_folder = folder + \"train/\"\n",
        "test_folder = folder + \"test/\"\n",
        "training_video = training_folder + \"video/\"\n",
        "test_video = test_folder + \"video/\"\n",
        "training_images = training_folder + \"images/\"\n",
        "test_images = test_folder + \"images/\"\n",
        "os.makedirs(training_folder, exist_ok=True)\n",
        "os.makedirs(test_folder, exist_ok=True)\n",
        "os.makedirs(training_video, exist_ok=True)\n",
        "os.makedirs(test_video, exist_ok=True)\n",
        "os.makedirs(training_images, exist_ok=True)\n",
        "os.makedirs(test_images, exist_ok=True)\n",
        "\n",
        "# check the length of the directories and that they contain the same things\n",
        "\n",
        "# all videos with fps=25\n",
        "\n",
        "# sources:\n",
        "# {'asl5200',     youtube.com\n",
        "# 'aslbrick',     mp4\n",
        "# 'asldeafined',  mp4\n",
        "# 'asllex',       youtu.be\n",
        "# 'aslpro',       swf\n",
        "# 'aslsearch',    mp4\n",
        "# 'aslsignbank',  mp4\n",
        "# 'aslu',         youtube.com\n",
        "# 'elementalasl', mov (like mp4 maybe?)\n",
        "# 'handspeak',    mp4\n",
        "# 'lillybauer',   youtube.com\n",
        "# 'nabboud',      youtube.com\n",
        "# 'northtexas',   youtube.com\n",
        "# 'scott',        youtube.com\n",
        "# 'signingsavvy', mp4\n",
        "# 'signschool',   mp4\n",
        "# 'spreadthesign',mp4\n",
        "# 'startasl',     mp4\n",
        "# 'valencia-asl'} youtube.com"
      ],
      "metadata": {
        "id": "p7P2WNJh7rIi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download youtube videos\n",
        "\n",
        "youtube_videos = ['asl5200', 'asllex', 'aslu', 'lillybauer', 'nabboud', 'northtexas', 'scott', 'valencia-asl']\n",
        "not_downloaded = 0\n",
        "tot_youtube_videos = 0\n",
        "downloaded = []\n",
        "\n",
        "for i, word in enumerate(tqdm(list(js_file['gloss']), desc='glosses')):\n",
        "  for j, instance in enumerate(js_file['instances'][i]):\n",
        "\n",
        "    video_id = js_file['instances'][i][j]['video_id']\n",
        "    url = js_file['instances'][i][j]['url']\n",
        "    source = js_file['instances'][i][j]['source']\n",
        "    split = js_file['instances'][i][j]['split']\n",
        "    filename = f\"{word}_{video_id}.mp4\"\n",
        "\n",
        "    if source in youtube_videos:\n",
        "      tot_youtube_videos += 1\n",
        "      output_path = training_video if split == 'train' else test_video\n",
        "      dest_path = os.path.join(output_path, filename)\n",
        "      if 'youtu.be/' in url:\n",
        "          continue\n",
        "\n",
        "      if os.path.exists(dest_path):\n",
        "        downloaded.append(video_id)\n",
        "        continue\n",
        "\n",
        "      ydl_opts = {\n",
        "        'outtmpl': dest_path,\n",
        "        'format': 'bestvideo+bestaudio/best',\n",
        "        'merge_output_format': 'mp4',\n",
        "        'quiet': True,\n",
        "        'sleep_interval_requests': 2,\n",
        "        'max_sleep_interval': 5\n",
        "        }\n",
        "      try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "          ydl.download([url])\n",
        "          downloaded.append(video_id)\n",
        "          print(video_id, 'DOWNLOADED')\n",
        "      except:\n",
        "        print(video_id)\n",
        "        not_downloaded += 1\n",
        "        continue"
      ],
      "metadata": {
        "id": "cioQr7UCGNnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(not_downloaded, tot_youtube_videos)\n",
        "print(downloaded)"
      ],
      "metadata": {
        "id": "K24NpCV6QaiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download non-youtube videos (mp4 or mov)\n",
        "\n",
        "youtube_videos = ['asl5200', 'asllex', 'aslu', 'lillybauer', 'nabboud', 'northtexas', 'scott', 'valencia-asl']\n",
        "\n",
        "for i, word in enumerate(tqdm(list(js_file['gloss']), desc='glosses')):\n",
        "  for j, instance in enumerate(js_file['instances'][i]):\n",
        "\n",
        "    video_id = js_file['instances'][i][j]['video_id']\n",
        "    url = js_file['instances'][i][j]['url']\n",
        "    source = js_file['instances'][i][j]['source']\n",
        "    split = js_file['instances'][i][j]['split']\n",
        "    filename = f\"{word}_{video_id}.mp4\"\n",
        "\n",
        "    if source not in youtube_videos:\n",
        "\n",
        "      output_path = training_video if split == 'train' else test_video\n",
        "      dest_path = os.path.join(output_path, filename)\n",
        "\n",
        "      # remove already downloaded but damaged videos\n",
        "      if os.path.exists(dest_path):\n",
        "        with open(dest_path, 'rb') as f:\n",
        "                header = f.read()\n",
        "                if b'<html' in header.lower() or b'403 Forbidden' in header:\n",
        "                  print(dest_path)\n",
        "                  os.remove(dest_path)\n",
        "\n",
        "      try:\n",
        "        resp = requests.get(url, stream=True)\n",
        "        # do not download damaged videos\n",
        "        if resp.status_code != 200:\n",
        "                    continue\n",
        "        # save downloaded videos\n",
        "        with open(dest_path, mode='wb') as f:\n",
        "            f.write(resp.content)\n",
        "      except:\n",
        "        continue"
      ],
      "metadata": {
        "id": "_0cpCM5ec2MC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c0f85f-fc10-4dc7-98d1-a90c3f6a8fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "glosses:   3%|▎         | 67/2000 [03:19<1:14:50,  2.32s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "import requests\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the JSON data\n",
        "js_file = pd.read_json(\"/content/drive/MyDrive/NLP/WLASL_v0.3.json\")\n",
        "url = js_file['instances'][0][0]['url']\n",
        "folder = \"/content/drive/MyDrive/NLP/dataset/\" + js_file['gloss'][0] + \"/video/\"\n",
        "instance = js_file['instances'][0][0]['video_id']\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "dest_file = folder + instance + \".mp4\"\n",
        "os.makedirs(os.path.dirname(dest_file), exist_ok=True)\n",
        "\n",
        "# Download the video\n",
        "resp = requests.get(url)\n",
        "with open(dest_file, mode=\"wb\") as f:\n",
        "  f.write(resp.content)\n",
        "# _________________________________________________________________________________________________________________________________________________\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(dest_file)\n",
        "\n",
        "# Get FPS and total frames from the video\n",
        "fps = js_file['instances'][0][0]['fps']\n",
        "cap.set(cv2.CAP_PROP_FPS, fps)\n",
        "\n",
        "curr_frame = 0\n",
        "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "while True:\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  if curr_frame % 10 == 0:\n",
        "    cv2_imshow(frame)\n",
        "    curr_folder = \"/content/drive/MyDrive/NLP/dataset/\" + js_file['gloss'][0] + \"/\" + instance\n",
        "    os.makedirs(curr_folder, exist_ok=True)\n",
        "    frame_name = curr_folder + \"/\" + str(curr_frame) + \".jpg\"\n",
        "    cv2.imwrite(frame_name, frame)\n",
        "  curr_frame += 1"
      ],
      "metadata": {
        "id": "wFBWLNZw03ri"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}