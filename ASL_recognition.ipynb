{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinaEmili/Sign_language/blob/main/ASL_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code inspired to\n",
        "\n",
        "https://github.com/AvishakeAdhikary/Realtime-Sign-Language-Detection-Using-LSTM-Model/blob/main/RealTimeSignLanguageDetection.ipynb"
      ],
      "metadata": {
        "id": "z4864mwIJuZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeY0eM3iPdbW"
      },
      "outputs": [],
      "source": [
        "# mount google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import LSTM\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "syDlsXWzPjzp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "OK5Ut4Anq4NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "js_file = pd.read_json(\"/content/drive/MyDrive/NLP/WLASL_v0.3.json\")\n",
        "folder = \"/content/drive/MyDrive/NLP/dataset/\"\n",
        "\n",
        "training_folder = folder + \"train/\"\n",
        "validation_folder = folder + \"val/\"\n",
        "test_folder = folder + \"test/\"\n",
        "\n",
        "training_video = training_folder + \"video/\"\n",
        "validation_video = validation_folder + \"video/\"\n",
        "test_video = test_folder + \"video/\"\n",
        "\n",
        "training_images = training_folder + \"images/\"\n",
        "validation_images = validation_folder + \"images/\"\n",
        "test_images = test_folder + \"images/\""
      ],
      "metadata": {
        "id": "FSJFrrsePo3B"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data"
      ],
      "metadata": {
        "id": "ciyIxRuPHyYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gloss, val_gloss, test_gloss = set(), set(), set()\n",
        "for image in os.listdir(training_images):\n",
        "  word, _ = image.split(\"_\") # rsplit(\"_\") removes the extension\n",
        "  train_gloss.add(word)\n",
        "\n",
        "for image in os.listdir(validation_images):\n",
        "  word, _ = image.split(\"_\")\n",
        "  val_gloss.add(word)\n",
        "\n",
        "for image in os.listdir(test_images):\n",
        "  word, _ = image.split(\"_\")\n",
        "  test_gloss.add(word)\n",
        "gloss = sorted(list(train_gloss | val_gloss | test_gloss))\n",
        "\n",
        "# the gloss 'wash face' is missing cause all the urls are broken\n",
        "\n",
        "label_map = {label: num for num, label in enumerate(gloss)}"
      ],
      "metadata": {
        "id": "y5ereGhDzrKe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_files = sorted(os.listdir(training_images))\n",
        "val_files = sorted(os.listdir(validation_images))\n",
        "test_files = sorted(os.listdir(test_images))\n",
        "\n",
        "def load_data(images, label_map):\n",
        "  X, y = [], []\n",
        "  corrupted_files = []\n",
        "  max_len = 0\n",
        "  for image in os.listdir(images):\n",
        "    np_array = np.load(os.path.join(images, image))\n",
        "    label, _ = image.split(\"_\")\n",
        "\n",
        "    if np_array.size == 0 or len(np_array.shape) < 2:\n",
        "      corrupted_files.append((image, np_array.shape))\n",
        "      continue\n",
        "\n",
        "    length = np_array.shape[0]\n",
        "    if length > max_len: max_len = length\n",
        "\n",
        "    X.append(np_array)\n",
        "    y.append(label_map[label])\n",
        "\n",
        "  padded_X = []\n",
        "  for np_array in X:\n",
        "    pad_length = max_len - np_array.shape[0]\n",
        "    padded_np_array = np.pad(np_array, ((0, pad_length), (0, 0)), mode='constant', constant_values=0) # add zero padding at the end\n",
        "    padded_X.append(padded_np_array)\n",
        "\n",
        "  X = torch.tensor(np.array(padded_X), dtype=torch.float32)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  return X, y\n",
        "\n",
        "num_classes = len(gloss)\n",
        "\n",
        "X_train, y_train = load_data(training_images, label_map)\n",
        "X_val, y_val = load_data(validation_images, label_map)\n",
        "X_test, y_test = load_data(test_images, label_map)"
      ],
      "metadata": {
        "id": "dHivL3dkfqO-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and train LSTM Neural Network"
      ],
      "metadata": {
        "id": "YVI0dkQFHtgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SignLanguageLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(SignLanguageLSTM, self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.lstm1 = nn.LSTM(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.lstm2 = nn.LSTM(\n",
        "        input_size=hidden_size,\n",
        "        hidden_size=hidden_size * 2,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.lstm3 = nn.LSTM(\n",
        "        input_size=hidden_size * 2,\n",
        "        hidden_size=hidden_size,\n",
        "        batch_first=True)\n",
        "\n",
        "    self.fc1 = nn.Linear(hidden_size, hidden_size * 2)\n",
        "    self.fc2 = nn.Linear(hidden_size * 2, hidden_size * 4)\n",
        "    self.fc3 = nn.Linear(hidden_size * 4, num_classes)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # LSTM 1\n",
        "    x, _ = self.lstm1(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # LSTM 2\n",
        "    x, _ = self.lstm2(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    # LSTM 3\n",
        "    x, _ = self.lstm3(x)\n",
        "    x = self.relu(x)\n",
        "\n",
        "    x = x[:, -1, :]\n",
        "\n",
        "    # fully connected layers\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "input_size = 258\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "model = SignLanguageLSTM(input_size, hidden_size, num_layers, num_classes)"
      ],
      "metadata": {
        "id": "dxjtMVDWRHZw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "validation_dataset = TensorDataset(X_val, y_val)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "3W63-xPsbuyu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = 0.0\n",
        "save_model = \"/content/drive/MyDrive/NLP/saved_models/\"\n",
        "os.makedirs(save_model, exist_ok=True)\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    print('-' * 30)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train() # enables dropout layers and batch normalization updates\n",
        "            loader = train_loader\n",
        "        else:\n",
        "            model.eval() # disables dropout layers and batch normalization updates\n",
        "            loader = validation_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            if phase == 'train':\n",
        "                optimizer.zero_grad() # clears accumulated gradients before each batch during training\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'): # enables gradient computation only during training, conserving memory during validation\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward() # calculates gradients through automatic differentiation\n",
        "                    optimizer.step() # updates model weights based on calculated gradients\n",
        "\n",
        "            running_loss += loss.item() # scalar value of the loss\n",
        "            _, predicted = torch.max(outputs, 1) # extract the predicted value taking the one with the higher score\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(loader)\n",
        "        epoch_acc = correct / total\n",
        "\n",
        "        print(f\"{phase.upper()} Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.4f}\")\n",
        "\n",
        "        # Save best model based on validation accuracy\n",
        "        if phase == 'val' and epoch_acc > best_val_acc:\n",
        "            best_val_acc = epoch_acc\n",
        "            torch.save(model.state_dict(), f\"{save_model}/best_model.pt\")\n",
        "            print(\"Saved new best model\")\n",
        "\n",
        "# Final Test Evaluation\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        test_correct += (predicted == labels).sum().item()\n",
        "        test_total += labels.size(0)\n",
        "\n",
        "test_acc = test_correct / test_total\n",
        "print(f\"\\nTEST Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "tjvpkLURfjqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}