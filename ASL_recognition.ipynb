{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinaEmili/Sign_language/blob/main/ASL_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "code inspired to\n",
        "\n",
        "https://github.com/AvishakeAdhikary/Realtime-Sign-Language-Detection-Using-LSTM-Model/blob/main/RealTimeSignLanguageDetection.ipynb\n",
        "\n",
        "https://medium.com/@santosjoaopedro/exploring-word-level-sign-language-recognition-with-lstms-6c6e60711968"
      ],
      "metadata": {
        "id": "z4864mwIJuZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MeY0eM3iPdbW",
        "outputId": "a9109303-799d-4a9e-f24d-f3ff1e9a515e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence, pad_packed_sequence\n",
        "from torch.nn import LSTM\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset"
      ],
      "metadata": {
        "id": "syDlsXWzPjzp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "OK5Ut4Anq4NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "js_file = pd.read_json(\"/content/drive/MyDrive/NLP/WLASL_v0.3.json\")\n",
        "folder = \"/content/drive/MyDrive/NLP/dataset/\"\n",
        "\n",
        "training_folder = folder + \"train/\"\n",
        "validation_folder = folder + \"val/\"\n",
        "test_folder = folder + \"test/\"\n",
        "\n",
        "training_video = training_folder + \"video/\"\n",
        "validation_video = validation_folder + \"video/\"\n",
        "test_video = test_folder + \"video/\"\n",
        "\n",
        "training_images = training_folder + \"images/\"\n",
        "validation_images = validation_folder + \"images/\"\n",
        "test_images = test_folder + \"images/\""
      ],
      "metadata": {
        "id": "FSJFrrsePo3B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data"
      ],
      "metadata": {
        "id": "ciyIxRuPHyYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gloss, val_gloss, test_gloss = set(), set(), set()\n",
        "for image in os.listdir(training_images):\n",
        "  word, _ = image.split(\"_\") # rsplit(\"_\") removes the extension\n",
        "  train_gloss.add(word)\n",
        "\n",
        "for image in os.listdir(validation_images):\n",
        "  word, _ = image.split(\"_\")\n",
        "  val_gloss.add(word)\n",
        "\n",
        "for image in os.listdir(test_images):\n",
        "  word, _ = image.split(\"_\")\n",
        "  test_gloss.add(word)\n",
        "gloss = sorted(list(train_gloss | val_gloss | test_gloss))\n",
        "\n",
        "# the gloss 'wash face' and 'boots' are missing cause all the urls are broken\n",
        "\n",
        "label_map = {label: num for num, label in enumerate(gloss)}"
      ],
      "metadata": {
        "id": "y5ereGhDzrKe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SignLanguageDataset(Dataset):\n",
        "  def __init__(self, image_dir, label_map):\n",
        "     self.image_dir = image_dir\n",
        "     self.label_map = label_map\n",
        "     self.files = sorted(os.listdir(image_dir))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_name = self.files[idx]\n",
        "    np_array = np.load(os.path.join(self.image_dir, file_name))\n",
        "    if np_array.size == 0 or len(np_array.shape) != 2 or np_array.shape[1] != 258:\n",
        "      print(f\"Warning: Empty or invalid shape for file: {file_name}\")\n",
        "      np_array = np.zeros((1, 258), dtype=np.float32)\n",
        "\n",
        "    label, _ = file_name.split(\"_\")\n",
        "    label = self.label_map[label]\n",
        "\n",
        "    return torch.tensor(np_array, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Add zero-padding to get sequences of the same length for each batch\n",
        "def collate_fn(batch):\n",
        "  sequences, labels = zip(*batch)\n",
        "  lengths = [len(seq) for seq in sequences]\n",
        "  padded_sequences = pad_sequence(sequences, batch_first=True)\n",
        "\n",
        "  # pack the padded sequence\n",
        "  packed_sequences = pack_padded_sequence(padded_sequences, lengths, batch_first=True, enforce_sorted=False)\n",
        "  return packed_sequences, torch.tensor(labels)\n",
        "\n",
        "train_dataset = SignLanguageDataset(training_images, label_map)\n",
        "val_dataset = SignLanguageDataset(validation_images, label_map)\n",
        "test_dataset = SignLanguageDataset(test_images, label_map)\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=4)"
      ],
      "metadata": {
        "id": "YVYgTK6P5PKA",
        "outputId": "4af7b2af-939d-4cbd-80b9-eaf55b4f9d06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and train LSTM Neural Network"
      ],
      "metadata": {
        "id": "YVI0dkQFHtgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SignLanguageLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes, dropout_rate=0.5):\n",
        "    super(SignLanguageLSTM, self).__init__()\n",
        "\n",
        "    # input regularization\n",
        "    self.input_bn = nn.BatchNorm1d(input_size)\n",
        "    self.input_dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # single bidirectional LSTM layer\n",
        "    self.lstm = nn.LSTM(\n",
        "        input_size=input_size,\n",
        "        hidden_size=hidden_size,\n",
        "        batch_first=True,\n",
        "        dropout=dropout_rate,\n",
        "        bidirectional=True)\n",
        "\n",
        "    # fully connected layers\n",
        "    self.fc1 = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, packed_input):\n",
        "    # unpack input for batch normalization\n",
        "    padded_input, lengths = pad_packed_sequence(packed_input, batch_first=True)\n",
        "\n",
        "    # apply input normalization and dropout\n",
        "    padded_input = padded_input.transpose(1, 2)\n",
        "    padded_input = self.input_bn(padded_input)\n",
        "    padded_input = padded_input.transpose(1, 2)\n",
        "    padded_input = self.input_dropout(padded_input)\n",
        "\n",
        "    # re-pack input\n",
        "    packed_input = pack_padded_sequence(padded_input, lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "    # LSTM\n",
        "    packed_output, (hn, cn) = self.lstm(packed_input)\n",
        "\n",
        "    output_forward = hn[0, :, :]\n",
        "    output_backward = hn[1, :, :]\n",
        "    output = torch.cat((output_forward, output_backward), dim=1)\n",
        "\n",
        "    # fully connected layers\n",
        "    output = F.relu(self.fc1(output))\n",
        "    output = self.fc2(self.dropout(output))\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "9X0Y9H6F2QLC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training configuration tailored for small datasets\n",
        "def get_training_config():\n",
        "  return {\n",
        "    'hidden_size': 2048,\n",
        "    'learning_rate': 1e-2,\n",
        "    'num_epochs': 100,\n",
        "    'weight_decay': 1e-3,\n",
        "    'dropout_rate': 0.3,\n",
        "    'scheduler_params': {\n",
        "      'factor': 0.5,\n",
        "      'min_lr': 1e-6\n",
        "    },\n",
        "  }\n",
        "\n",
        "best_accuracy = 0.0\n",
        "training_history = []\n",
        "config = get_training_config()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = config['num_epochs']\n",
        "\n",
        "model = SignLanguageLSTM(\n",
        "    input_size=258,\n",
        "    hidden_size = config['hidden_size'],\n",
        "    num_classes = len(label_map),\n",
        "    dropout_rate=config['dropout_rate']).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # for multi-class classification\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(),\n",
        "    lr=config['learning_rate'],\n",
        "    weight_decay=config['weight_decay'])\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=config['scheduler_params']['factor'],\n",
        "    min_lr=config['scheduler_params']['min_lr'],\n",
        "    patience=5)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "\n",
        "  for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Train]'):\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  avg_train_loss = running_loss / len(train_loader)\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "  # evaluation phase\n",
        "  model.eval()\n",
        "  val_loss, correct, total = 0, 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in tqdm(val_loader, desc=f'Epoch {epoch + 1}/{num_epochs} [Valid]'):\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)\n",
        "      val_loss += loss.item()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "  accuracy = correct / total\n",
        "  avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "  # update learning rate based on validation accuracy\n",
        "  scheduler.step(accuracy)\n",
        "\n",
        "  print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
        "  print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "  # store training history\n",
        "  training_history.append({\n",
        "    'epoch': epoch + 1,\n",
        "    'train_loss': avg_train_loss,\n",
        "    'val_loss': avg_val_loss,\n",
        "    'acc': accuracy,\n",
        "    'lr': optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "  # save best model\n",
        "  if accuracy > best_accuracy:\n",
        "    best_accuracy = accuracy\n",
        "    torch.save({\n",
        "      'epoch': epoch,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'accuracy': accuracy,\n",
        "    }, '/content/drive/MyDrive/NLP/saved_models/best_model.pth')\n",
        "    print(f'Saved new best model with accuracy: {best_accuracy * 100:.2f}%\\n-----')\n",
        "# --------------------------------------------------\n",
        "\n",
        "#model.eval()\n",
        "#correct, total = 0, 0\n",
        "#with torch.no_grad():\n",
        "#  for inputs, labels in test_loader:\n",
        "#    outputs = model(inputs)\n",
        "#    _, predicted = torch.max(outputs, 1)\n",
        "#    total += labels.size(0)\n",
        "#    correct += (predicted == labels).sum().item()\n",
        "#test_accuracy = correct / total  # Test accuracy\n",
        "#print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "A70SeTZD-twO",
        "outputId": "08b387d5-0972-4cee-d86e-0b42ceb4c9af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]: 100%|██████████| 441/441 [02:26<00:00,  3.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 8.8581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Valid]: 100%|██████████| 78/78 [17:19<00:00, 13.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.04%\n",
            "Epoch [1/100], Validation Loss: 9.2150\n",
            "Saved new best model with accuracy: 0.04%\n",
            "-----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 [Train]: 100%|██████████| 441/441 [02:37<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/100], Loss: 8.4468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100 [Valid]: 100%|██████████| 78/78 [00:10<00:00,  7.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.12%\n",
            "Epoch [2/100], Validation Loss: 9.1816\n",
            "Saved new best model with accuracy: 0.12%\n",
            "-----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 [Train]: 100%|██████████| 441/441 [02:49<00:00,  2.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/100], Loss: 8.0112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 [Valid]: 100%|██████████| 78/78 [00:11<00:00,  6.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.08%\n",
            "Epoch [3/100], Validation Loss: 9.7979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 [Train]: 100%|██████████| 441/441 [02:40<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/100], Loss: 8.5308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100 [Valid]: 100%|██████████| 78/78 [00:11<00:00,  6.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.08%\n",
            "Epoch [4/100], Validation Loss: 9.2456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 [Train]: 100%|██████████| 441/441 [02:40<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/100], Loss: 7.9399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 [Valid]: 100%|██████████| 78/78 [00:11<00:00,  6.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.00%\n",
            "Epoch [5/100], Validation Loss: 9.1498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 [Train]: 100%|██████████| 441/441 [02:41<00:00,  2.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/100], Loss: 7.6802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100 [Valid]: 100%|██████████| 78/78 [00:11<00:00,  6.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.08%\n",
            "Epoch [6/100], Validation Loss: 9.1598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 [Train]:  36%|███▋      | 160/441 [00:58<01:40,  2.80it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- try to add weights nn.CrossEntropyLoss(weight=class_weights)\n",
        "- try to change learning rate lr=0.0001\n",
        "- inputs = (inputs - inputs.mean()) / inputs.std()\n",
        "- dropout=0.2, self.dropout = nn.Dropout(p=0.5)\n",
        "out = self.relu(self.fc1(out))\n",
        "out = self.dropout(out)  # Dropout after the first FC layer\n",
        "out = self.fc2(out)\n",
        "- training for More Epochs\n"
      ],
      "metadata": {
        "id": "qMuZh4J0TXKv"
      }
    }
  ]
}